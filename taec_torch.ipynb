{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imp\n",
    "import time\n",
    "import os\n",
    "\n",
    "import utils.movie_readin as mru\n",
    "import utils.plotutils as plu\n",
    "import utils.model as mod\n",
    "#import utils.model_analysis as man\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie parameters\n",
    "frame_rate = 120\n",
    "patch_size = 32\n",
    "patch_seconds = 5\n",
    "patch_frames = patch_seconds * frame_rate\n",
    "movies_folder = '/data/stationary_motion/pixel2xlmomentlens/pngs'\n",
    "patches_folder = f'/data/stationary_motion/pixel2xlmomentlens/patches/patches_{patch_size}px_{patch_seconds}s_{frame_rate}fps'\n",
    "\n",
    "# model params\n",
    "lambda_activation = ['mean1pnpi']\n",
    "lambda_biophysical = 0\n",
    "conv_width = 8\n",
    "num_hidden_nodes = [25]\n",
    "#weight_decays = [1]\n",
    "\n",
    "# training hyperparameters\n",
    "num_epochs = 500\n",
    "batch_size = 150\n",
    "learning_rates = [1e-4]\n",
    "learning_momentums = [0.95, 0.99]\n",
    "optimizer_types = ['sgd']\n",
    "\n",
    "#reporting parameters\n",
    "print_epocs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Patches are already loaded in - Please be sure they are the correct shape!\n"
     ]
    }
   ],
   "source": [
    "imp.reload(mru)\n",
    "if not 'movie_dataset' in globals():\n",
    "    try:\n",
    "        os.stat(patches_folder)\n",
    "        print('Found Pre-computed natural movie patches. Loading them in...')\n",
    "    except:\n",
    "        print('Couldn\\'t find natual movie patches. Making them...')\n",
    "        mru.createNatMoviePatches(framerate=frame_rate, patchsize=patch_size, seconds=patch_seconds,\n",
    "                              read_folder=movies_folder, write_folder=patches_folder, patches_per_file=100000)\n",
    "        print('Done Making Patches. Loading them in....')\n",
    "    movie_dataset = mru.get_pkl_patch_movie(patches_folder)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print('Movie Patches are already loaded in - Please be sure they are the correct shape!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:32^2  = 1024 pixels by 5 frames, to 25 hidden nodes for 40.96x compression\n",
      "Optimizer:sgd; Conv Width:8; Hidden Nodes:25; Lambda Act:['mean1pnpi'];Learning Rate:0.0001; Batch Size:150; Momentum:0.95\n",
      "Training 500 Epochs. Estimated run time: 208.2mins.\n",
      "**********"
     ]
    }
   ],
   "source": [
    "imp.reload(mod)\n",
    "imp.reload(mru)\n",
    "\n",
    "for num_hidden_node in num_hidden_nodes:\n",
    "    compression = patch_size**2 / num_hidden_node\n",
    "    print(f'Model:{patch_size}^2  = {patch_size**2} pixels by {patch_seconds} frames, to {num_hidden_node} hidden nodes for {compression}x compression')\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "\n",
    "\n",
    "        for optimizer_type in optimizer_types:\n",
    "\n",
    "            for learning_momentum in learning_momentums:\n",
    "\n",
    "                #record current param setting\n",
    "                print(f'Optimizer:{optimizer_type}; Conv Width:{conv_width}; Hidden Nodes:{num_hidden_node}; Lambda Act:{lambda_activation};Learning Rate:{learning_rate}; Batch Size:{batch_size}; Momentum:{learning_momentum}')        \n",
    "                params = f'{optimizer_type}_conv{conv_width}_hn{num_hidden_node}_lact{lambda_activation}_lr{learning_rate}_bs{batch_size}_mm{learning_momentum}'\n",
    "                save_folder = os.path.join('./output',params)\n",
    "                if not os.path.exists(save_folder):\n",
    "                    os.mkdir(save_folder)\n",
    "\n",
    "                #define model\n",
    "                model = mod.AEC(num_hidden_node, conv_width, patch_size, lambda_activation)\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                if torch.cuda.is_available():\n",
    "                    #print('Found GPU - Running Model on it.')\n",
    "                    model.cuda()\n",
    "\n",
    "                #define optimizer\n",
    "                if(optimizer_type == 'adam'):\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                elif(optimizer_type == 'sgd'):\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=learning_momentum)\n",
    "\n",
    "                #train over epochs\n",
    "                print(f'Training {num_epochs} Epochs. ',end=\"\")\n",
    "                printing_modulo = num_epochs/print_epocs\n",
    "                loss_history = []\n",
    "                snr_history = []\n",
    "\n",
    "                # Because we have a badass machine, it's faster to read all into memory \n",
    "                for i in range(num_epochs):\n",
    "                    start = time.time()\n",
    "                    times = []\n",
    "                    batches_start = np.arange(0,np.shape(movie_dataset)[0], batch_size)\n",
    "                    for bs in batches_start:\n",
    "                        movie_batch = torch.unsqueeze(torch.tensor(movie_dataset[bs:bs+batch_size]),1).cuda()          \n",
    "                        optimizer.zero_grad() #zero out our gradients\n",
    "                        acts = model.encode(movie_batch)\n",
    "                        recon_batch = model.decode(acts)\n",
    "                        loss = model.loss_func(movie_batch, recon_batch, acts)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        end = time.time()\n",
    "                        times.append(end-start)\n",
    "                    # record loss and snr after each epoch\n",
    "                    loss_history.append(loss.item())\n",
    "                    snr_history.append(model.calc_snr(movie_batch, recon_batch).detach())\n",
    "                    # if it's our first iteration, give an estimate of time\n",
    "                    if(i==0):\n",
    "                        plt.clf()\n",
    "                        print(f'Estimated run time: {round(times[-1]*num_epochs/60,1)}mins.')\n",
    "                    elif((i+1)%printing_modulo==0):\n",
    "                        print(f'Epoch {i+1}/{num_epochs} (mean time per epoch: {round(np.mean(times),1)}s)')\n",
    "                        for name, parameter in model.named_parameters():\n",
    "                            if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "                                inw = np.array(parameter.cpu().squeeze().detach())\n",
    "                            elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "                                outw = np.array(parameter.cpu().squeeze().detach())\n",
    "                        p = plu.plot_temporal_weights(inw)\n",
    "                        plt.savefig(os.path.join(save_folder,f'inw_{params}_{round(i/num_epochs,2)}.png'))\n",
    "                        plt.show()\n",
    "                        p = plu.plot_temporal_weights(outw)\n",
    "                        plt.savefig(os.path.join(save_folder,f'outw_{params}_{round(i/num_epochs,2)}.png'))\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        print('*',end='')\n",
    "\n",
    "                #get final weights & losses\n",
    "                for name, parameter in model.named_parameters():\n",
    "                    if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "                        inw = np.array(parameter.cpu().squeeze().detach())\n",
    "                    elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "                        outw = np.array(parameter.cpu().squeeze().detach())\n",
    "                loss_evolution = [np.float(loss) for loss in loss_history]\n",
    "                snr_evolution =  [np.float(snr) for snr in snr_history]\n",
    "\n",
    "                # plot everything\n",
    "                p = plu.plot_temporal_weights(inw)\n",
    "                plt.savefig(os.path.join(save_folder,f'final_inw_{params}.png'))\n",
    "                plt.clf()\n",
    "                p = plu.plot_temporal_weights(outw)\n",
    "                plt.savefig(os.path.join(save_folder,f'final_outw_{params}.png'))\n",
    "                plt.clf()\n",
    "                plt.plot(loss_evolution)\n",
    "                plt.title('Loss Evolution')\n",
    "                plt.savefig(os.path.join(save_folder,f'final_loss_{params}.png'))\n",
    "                plt.clf()\n",
    "                plt.plot(np.log(loss_evolution))\n",
    "                plt.title('Log Loss Evolution')\n",
    "                plt.savefig(os.path.join(save_folder,f'final_lgloss_{params}.png'))\n",
    "                plt.clf()\n",
    "                p = plt.plot(snr_evolution)\n",
    "                plt.title('SNR Evolution')\n",
    "                plt.savefig(os.path.join(save_folder,f'final_snr_{params}.png'))\n",
    "                plt.clf()\n",
    "                plt.figure()\n",
    "                for i in range(10):\n",
    "                    plu.plot_movies_recons(np.squeeze(movie_batch), np.squeeze(recon_batch), i)\n",
    "                plt.savefig(os.path.join(save_folder,f'finaol_recons_{params}.png'))\n",
    "\n",
    "                print('Finished this Parameter')\n",
    "\n",
    "print('Finished Sweep!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_evolution = [loss for loss in loss_history]\n",
    "plt.plot(loss_evolution)\n",
    "plt.show()\n",
    "plt.plot(np.log(loss_evolu\n",
    "                tion))\n",
    "plt.show()\n",
    "plt.plot(np.log(snr_history))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_memory():\n",
    "    import collections, gc, torch\n",
    "    tensors = collections.Counter((str(o.device), o.dtype, tuple(o.shape))\n",
    "                                  for o in gc.get_objects()\n",
    "                                  if torch.is_tensor(o))\n",
    "    for line in sorted(tensors.items()):\n",
    "        print('{}\\t{}'.format(*line))\n",
    "debug_memory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name)\n",
    "    if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "        inw = np.array(parameter.squeeze().detach().cpu())\n",
    "    elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "        outw = np.array(parameter.squeeze().detach().cpu())\n",
    "    #elif(name=='tconv.weight_g'):\n",
    "    #    print(np.shape(np.array(parameter.squeeze().detach())))\n",
    "\n",
    "#print(inw.shape)\n",
    "#print(bias.shape)\n",
    "#print(wnorm.shape)\n",
    "#print(outw.shape)\n",
    "p = plu.plot_temporal_weights(inw)\n",
    "p = plu.plot_temporal_weights(outw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(inw.flatten())\n",
    "plt.hist(outw.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(plu)\n",
    "#movies = movie_batch[0]\n",
    "#recons = recon_batch[0]\n",
    "print('Movies:')\n",
    "for i in range(10):\n",
    "    plu.plot_movies_recons(np.squeeze(movie_batch), np.squeeze(recon_batch), i)\n",
    "    #plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inw.shape)\n",
    "print(np.max(inw))\n",
    "print(np.min(inw))\n",
    "for i in range(inw.shape[1]):\n",
    "    plt.imshow(inw[9,i,:,:],cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie.shape)\n",
    "m = movie[7,0,1,:,:]\n",
    "plt.imshow(m)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    moreepochs = 2000\n",
    "    print(f'Training for {moreepochs} more Epochs:')\n",
    "    for i in range(moreepochs):\n",
    "        start = time.time()\n",
    "        times = []\n",
    "        for movie in train_loader:\n",
    "            movie = torch.unsqueeze(movie,1)\n",
    "            #print(movie.size())\n",
    "            movie = movie.float().cuda()\n",
    "            optimizer.zero_grad()\n",
    "            acts = model.encode(movie)\n",
    "            recon = model.decode(acts)\n",
    "            loss = loss_func(movie, recon, acts)\n",
    "            loss_history.append(loss.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            end=time.time()\n",
    "            times.append(end-start)\n",
    "            \n",
    "        if((i+1)%printing_modulo==0):\n",
    "            print(f'{i+1}th Epoch (mean time per epoch: {round(np.mean(times))}s)')\n",
    "        else:\n",
    "            print('*',end='')\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aec():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(train_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.encode(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Recon Images')\n",
    "\n",
    "\n",
    "visualize_aec()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.make_grid(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "plt.ion()   # continuously plot\n",
    "\n",
    "# original data (first row) for viewing\n",
    "view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "    \n",
    "    \n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, b_label) in enumerate(train_loader):\n",
    "        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n",
    "        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.numpy())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            for i in range(N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "#\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEC()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
