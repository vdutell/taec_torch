{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import imp\n",
    "import utils.movie_readin as mru\n",
    "import utils.plotutils as plu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:12^2 pixels by 120 frames, to 1728 hidden nodes for 10x compression\n",
      "normalizing movie...\n",
      "making patches...\n",
      "(64240, 12, 12, 120)\n"
     ]
    }
   ],
   "source": [
    "#movie parameters\n",
    "movie_filepath = '/home/vasha/research/datasets/stationary_motion/pixel2xlmomentlens/full_framerate/purple_willows_120.mp4_120fps.mp4'\n",
    "pixel_patchsize = 12\n",
    "frame_patchsize = 120\n",
    "maxframes = 960\n",
    "# read in the movie\n",
    "#willows = mru.get_movie(movie_filepath, pixel_patchsize, frame_patchsize,\n",
    "#                          normalize_patch=False, normalize_movie=True, encoding='mp4')\n",
    "# plot a test movie\n",
    "#test = willows[10,0,:,:]\n",
    "#plt.imshow(test)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 5000\n",
    "batch_size = 100\n",
    "learning_rate = 1e-5\n",
    "N_TEST_IMG = 5\n",
    "lambda_activation = 0.01\n",
    "lambda_biophysical = 0.01\n",
    "\n",
    "# model parameters\n",
    "conv_width = 7\n",
    "compression = 10\n",
    "hidden_nodes = int(pixel_patchsize**2 * frame_patchsize / compression)\n",
    "print(f'Training model:{pixel_patchsize}^2 pixels by {frame_patchsize} frames, to {hidden_nodes} hidden nodes for {compression}x compression')\n",
    "\n",
    "\n",
    "# make it a Pytorch dataset (inherits from Dataset)\n",
    "class NaturalMovieDataset(Dataset):\n",
    "    \"\"\"Dataset of Stationary Naural Movies\"\"\"\n",
    "    \n",
    "    def __init__(self, movie_filepath, pixel_patchsize, frame_patchsize,\n",
    "                     normalize_patch=False, normalize_movie=True, encoding='mp4'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            movie_filepath (string): Path to the movie file\n",
    "            pixel_patchsize (int): Number of pixels on the edge of a patch\n",
    "            frame_patchsize (int): Number of frames in the movie\n",
    "        \"\"\"\n",
    "        self.movies = mru.get_movie(movie_filepath, pixel_patchsize, maxframes, frame_patchsize,\n",
    "                          normalize_patch=False, normalize_movie=True, encoding='mp4',\n",
    "                          crop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.movies)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        movie = self.movies[idx,:,:,:]\n",
    "        movie = torch.from_numpy(movie)\n",
    "        sample = Variable(movie)\n",
    "        return sample\n",
    "\n",
    "try:\n",
    "    movie_dataset\n",
    "except NameError:    \n",
    "    movie_dataset = NaturalMovieDataset(movie_filepath, pixel_patchsize, frame_patchsize,\n",
    "                              normalize_patch=False, normalize_movie=True, encoding='mp4')\n",
    "\n",
    "    train_loader = DataLoader(movie_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epochs:"
     ]
    }
   ],
   "source": [
    "class AEC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEC, self).__init__()\n",
    "        \n",
    "        temporal_conv_kernel_size = (conv_width, pixel_patchsize, pixel_patchsize)\n",
    "\n",
    "        self.tconv = nn.Conv3d(1,\n",
    "                               hidden_nodes, \n",
    "                               kernel_size=temporal_conv_kernel_size,\n",
    "                               stride=1)\n",
    "        self.tdeconv = nn.ConvTranspose3d(hidden_nodes,\n",
    "                                          1,\n",
    "                                          kernel_size = np.transpose(temporal_conv_kernel_size),\n",
    "                                          stride=1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        activations = F.relu(self.tconv(x))\n",
    "        return activations\n",
    "\n",
    "    def decode(self, z):\n",
    "        recon = self.tdeconv(z)\n",
    "        return recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = self.encode(x)\n",
    "        #z = self.reparametrize(mu, logvar)\n",
    "        decoded = self.decode(activations)\n",
    "        return activations, decoded\n",
    "    \n",
    "# our model\n",
    "model = AEC()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
    "\n",
    "def loss_func(x, xhat, activations):\n",
    "        recon_loss = ((x-xhat)**2).mean()\n",
    "        activation_loss = torch.sum(activations * lambda_activation)\n",
    "        loss = recon_loss + activation_loss\n",
    "        return(loss)\n",
    "\n",
    "loss_history = []\n",
    "print('Training Epochs:', end='')\n",
    "for i in range(num_epochs):\n",
    "    for movie in train_loader:\n",
    "        movie = torch.unsqueeze(movie,1)\n",
    "        #print(movie.size())\n",
    "        movie = Variable(movie.float()).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        acts = model.encode(movie)\n",
    "        recon = model.decode(acts)\n",
    "        loss = loss_func(movie, recon, acts)\n",
    "        loss_history.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(i%10==0):\n",
    "        print(f'{i}', end='')\n",
    "    else:\n",
    "        print('*',end='')\n",
    "print('Done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = model.parameters()\n",
    "inw = next(mp).squeeze()\n",
    "bias = next(mp)\n",
    "outw = next(mp).squeeze()\n",
    "\n",
    "print(inw.shape)\n",
    "print(bias.shape)\n",
    "print(outw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(plu)\n",
    "print('Kernels:')\n",
    "for i in range(5,10):\n",
    "    #print(f'Kernel {i}:')\n",
    "    plu.plot_temporal_rf(inw, i, vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_evolution = [np.float(loss.detach()) for loss in loss_history]\n",
    "plt.plot(loss_evolution)\n",
    "plt.show()\n",
    "plt.plot(np.log(loss_evolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Movies:')\n",
    "for i in range(5):\n",
    "    plu.plot_movies_recons(np.squeeze(movie), np.squeeze(recon), i)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aec():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(train_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.encode(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Recon Images')\n",
    "\n",
    "\n",
    "visualize_aec()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.make_grid(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "plt.ion()   # continuously plot\n",
    "\n",
    "# original data (first row) for viewing\n",
    "view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "    \n",
    "    \n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, b_label) in enumerate(train_loader):\n",
    "        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n",
    "        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            for i in range(N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "#\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEC()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
