{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imp\n",
    "import time\n",
    "import os\n",
    "import itertools as it\n",
    "import imp\n",
    "\n",
    "\n",
    "import utils.movie_readin as mru\n",
    "import utils.plotutils as plu\n",
    "import utils.model as mod\n",
    "import utils.dataset as vdataset\n",
    "#import utils.model_analysis as man\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvideotransforms import video_transforms, volume_transforms\n",
    "\n",
    "\n",
    "#torch.cuda.set_device(0)\n",
    "cuda_device = ('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie parameters\n",
    "frame_rate = 15\n",
    "patch_size = 32\n",
    "patch_seconds = 5\n",
    "patch_frames = patch_seconds * frame_rate\n",
    "movies_folder = '/data/vasha/duckmovie/ducks2_128_finalOut'\n",
    "\n",
    "# model params\n",
    "lambda_activations = [1., 100.]\n",
    "lambda_biophysical = 0\n",
    "conv_width = 10\n",
    "num_hidden_nodes = [64]\n",
    "noises = [0]\n",
    "\n",
    "# training hyperparameters\n",
    "num_epochs = 1000\n",
    "batch_size = 5\n",
    "learning_rates = [1e-4]\n",
    "optimizer_types = ['adam']\n",
    "\n",
    "#reporting parameters\n",
    "print_epocs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(vdataset)\n",
    "my_transforms = video_transforms.Compose([video_transforms.RandomCrop(patch_size)])\n",
    "\n",
    "video_dataset = vdataset.VideoDataset(path=movies_folder, nframes=patch_frames, patch_size=patch_size, data_type='ducks', transform=None)\n",
    "video_dataloader = DataLoader(video_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fab677c5a10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j, video in enumerate(video_dataloader):\n",
    "    frames = video['frames']\n",
    "    break;\n",
    "    \n",
    "plt.hist(np.array(frames).flatten(),bins=100)\n",
    "plt.show()\n",
    "plt.imshow(np.array(frames[0,0,0,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:32^2  = 1024 pixels by 10 frames, to 64 hidden nodes for 16.0x compression\n",
      "Optimizer:adam; Conv Width:10; Hidden Nodes:64; Lambda Act:1.0;Learning Rate:0.0001; Batch Size:5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'psnr_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-51e88f33664e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mpsnr_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'psnr_history' is not defined"
     ]
    }
   ],
   "source": [
    "imp.reload(mod)\n",
    "\n",
    "iterator = it.product(num_hidden_nodes, learning_rates, lambda_activations, optimizer_types, noises)\n",
    "for iteration in iterator:\n",
    "    num_hidden_node, learning_rate, lambda_activation, optimizer_type, noise = iteration\n",
    "    compression = patch_size**2 / num_hidden_node\n",
    "    print(f'Model:{patch_size}^2  = {patch_size**2} pixels by {conv_width} frames, to {num_hidden_node} hidden nodes for {compression}x compression')\n",
    "    #record current param setting\n",
    "    print(f'Optimizer:{optimizer_type}; Conv Width:{conv_width}; Hidden Nodes:{num_hidden_node}; Lambda Act:{lambda_activation};Learning Rate:{learning_rate}; Batch Size:{batch_size}')        \n",
    "    params = f'{optimizer_type}_conv{conv_width}_hn{num_hidden_node}_lact{lambda_activation}_lr{learning_rate}_bs{batch_size}_noise{noise}'\n",
    "    save_folder = os.path.join('./output',params)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "    model = mod.AEC(num_hidden_node, conv_width, patch_size, lambda_activation, noise, cuda_device).to(cuda_device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_history = []\n",
    "    psnr_history = []\n",
    "    for i, epoch in enumerate(range(num_epochs)):\n",
    "        for j, video in enumerate(video_dataloader):\n",
    "            frames = video['frames'].to(cuda_device)\n",
    "            optimizer.zero_grad() #zero out our gradients\n",
    "            acts = model.encode(frames)\n",
    "            recon = model.decode(acts)\n",
    "            loss = model.loss_func(frames, recon, acts)\n",
    "            loss_history.append(loss)\n",
    "            psnr = model.calc_psnr(recon.cpu().detach().numpy(), frames.cpu().detach().numpy())\n",
    "            psnr_history.append(psnr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if((j+1)%print_epocs==0):\n",
    "                print(f'Epoch {i+1}/{num_epochs}')\n",
    "                for name, parameter in model.named_parameters():\n",
    "                    if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "                        inw = np.array(parameter.cpu().squeeze().detach())\n",
    "                    elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "                        outw = np.array(parameter.cpu().squeeze().detach())\n",
    "                #plot weigghts\n",
    "                p = plu.plot_temporal_weights(inw)\n",
    "                plt.savefig(os.path.join(save_folder,f'inw_{params}_{round(i/num_epochs,2)}.png'))\n",
    "                plt.show()\n",
    "                p = plu.plot_temporal_weights(outw)\n",
    "                plt.savefig(os.path.join(save_folder,f'outw_{params}_{round(i/num_epochs,2)}.png'))\n",
    "                plt.show()\n",
    "                #plot stats\n",
    "                plt.figure(figsize=(30,5))\n",
    "                plt.subplot(1,5,1)\n",
    "                p = plt.hist(np.array(acts.cpu().squeeze().detach()).flatten(),bins=100)\n",
    "                plt.title('Activations')\n",
    "                plt.subplot(1,5,2)\n",
    "                loss_evolution = [np.float(loss) for loss in loss_history]\n",
    "                plt.plot(loss_evolution)\n",
    "                plt.title('Loss Evolution')\n",
    "                plt.subplot(1,5,3)\n",
    "                psnr_evolution = [np.float(psnr) for psnr in psnr_history]\n",
    "                plt.plot(psnr_evolution)\n",
    "                plt.title('PSNR')\n",
    "                plt.subplot(1,5,4)\n",
    "                plt.imshow(frames[0,0,0,:,:].cpu().detach().numpy())\n",
    "                plt.title('Input Frame')\n",
    "                plt.subplot(1,5,5)\n",
    "                plt.imshow(recon[0,0,0,:,:].cpu().detach().numpy())\n",
    "                plt.title('Recon Frame')\n",
    "                plt.savefig(os.path.join(save_folder,f'stats_{params}.png'))\n",
    "                plt.show()\n",
    "            else:\n",
    "                print('*',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = it.product(num_hidden_nodes, learning_rates, lambda_activations, optimizer_types, learning_momentums, noises)\n",
    "\n",
    "for iteration in iterator:\n",
    "    num_hidden_node, learning_rate, lambda_activation, optimizer_type, learning_momentum, noise = iteration\n",
    "    compression = patch_size**2 / num_hidden_node\n",
    "    print(f'Model:{patch_size}^2  = {patch_size**2} pixels by {patch_seconds} frames, to {num_hidden_node} hidden nodes for {compression}x compression')\n",
    "    #record current param setting\n",
    "    print(f'Optimizer:{optimizer_type}; Conv Width:{conv_width}; Hidden Nodes:{num_hidden_node}; Lambda Act:{lambda_activation};Learning Rate:{learning_rate}; Batch Size:{batch_size}; Momentum:{learning_momentum}')        \n",
    "    params = f'{optimizer_type}_conv{conv_width}_hn{num_hidden_node}_lact{lambda_activation}_lr{learning_rate}_bs{batch_size}_mm{learning_momentum}_noise{noise}'\n",
    "    save_folder = os.path.join('./output',params)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "\n",
    "    #define model\n",
    "    model = mod.AEC(num_hidden_node, conv_width, patch_size, lambda_activation, noise)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        #print('Found GPU - Running Model on it.')\n",
    "        model.cuda()\n",
    "\n",
    "    #define optimizer\n",
    "    if(optimizer_type == 'adam'):\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif(optimizer_type == 'sgd'):\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=learning_momentum)\n",
    "\n",
    "    #train over epochs\n",
    "    print(f'Training {num_epochs} Epochs. ',end=\"\")\n",
    "    printing_modulo = num_epochs/print_epocs\n",
    "    loss_history = []\n",
    "    snr_history = []\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        batches_start = np.arange(0,np.shape(movie_dataset)[0], batch_size)\n",
    "        for bs in batches_start:\n",
    "            movie_batch = torch.unsqueeze(torch.tensor(movie_dataset[bs:bs+batch_size]),1).cuda()          \n",
    "            optimizer.zero_grad() #zero out our gradients\n",
    "            acts = model.encode(movie_batch)\n",
    "            recon_batch = model.decode(acts)\n",
    "            loss = model.loss_func(movie_batch, recon_batch, acts)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            end = time.time()\n",
    "            times.append(end-start)\n",
    "            # record loss and snr after each epoch\n",
    "            loss_history.append(loss.item())\n",
    "            snr_history.append(model.calc_psnr(movie_batch.cpu.cdetach(), recon_batch).detach())\n",
    "        # if it's our first iteration, give an estimate of time\n",
    "        if(i==0):\n",
    "            plt.clf()\n",
    "            print(f'Estimated run time: {round(times[-1]*num_epochs/60,1)}mins.')\n",
    "        elif((i+1)%printing_modulo==0):\n",
    "            print(f'Epoch {i+1}/{num_epochs} (mean time per epoch: {round(np.mean(times),1)}s)')\n",
    "            for name, parameter in model.named_parameters():\n",
    "                if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "                    inw = np.array(parameter.cpu().squeeze().detach())\n",
    "                elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "                    outw = np.array(parameter.cpu().squeeze().detach())\n",
    "            p = plt.hist(np.mean(np.array(acts.cpu().squeeze().detach()),axis=(0,2)))\n",
    "            p = plu.plot_temporal_weights(inw)\n",
    "            plt.savefig(os.path.join(save_folder,f'inw_{params}_{round(i/num_epochs,2)}.png'))\n",
    "            plt.show()\n",
    "            p = plu.plot_temporal_weights(outw)\n",
    "            plt.savefig(os.path.join(save_folder,f'outw_{params}_{round(i/num_epochs,2)}.png'))\n",
    "            plt.show()\n",
    "            loss_evolution = [np.float(loss) for loss in loss_history]\n",
    "            plt.plot(loss_evolution)\n",
    "            plt.title('Loss Evolution')\n",
    "            plt.savefig(os.path.join(save_folder,f'loss_evolution_{params}.png'))\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('*',end='')\n",
    "\n",
    "    #get final weights & losses\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "            inw = np.array(parameter.cpu().squeeze().detach())\n",
    "        elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "            outw = np.array(parameter.cpu().squeeze().detach())\n",
    "    loss_evolution = [np.float(loss) for loss in loss_history]\n",
    "    snr_evolution =  [np.float(snr) for snr in snr_history]\n",
    "\n",
    "    # plot everything\n",
    "    p = plu.plot_temporal_weights(inw)\n",
    "    plt.savefig(os.path.join(save_folder,f'final_inw_{params}.png'))\n",
    "    plt.clf()\n",
    "    p = plu.plot_temporal_weights(outw)\n",
    "    plt.savefig(os.path.join(save_folder,f'final_outw_{params}.png'))\n",
    "    plt.clf()\n",
    "    plt.plot(loss_evolution)\n",
    "    plt.title('Loss Evolution')\n",
    "    plt.savefig(os.path.join(save_folder,f'final_loss_{params}.png'))\n",
    "    plt.clf()\n",
    "    plt.plot(np.log(loss_evolution))\n",
    "    plt.title('Log Loss Evolution')\n",
    "    plt.savefig(os.path.join(save_folder,f'final_lgloss_{params}.png'))\n",
    "    plt.clf()\n",
    "    p = plt.plot(snr_evolution)\n",
    "    plt.title('SNR Evolution')\n",
    "    plt.savefig(os.path.join(save_folder,f'final_snr_{params}.png'))\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    for i in range(10):\n",
    "        plu.plot_movies_recons(np.squeeze(movie_batch), np.squeeze(recon_batch), i)\n",
    "    plt.savefig(os.path.join(save_folder,f'finaol_recons_{params}.png'))\n",
    "\n",
    "\n",
    "\n",
    "    print('Finished this Parameter')\n",
    "\n",
    "print('Finished Sweep!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_evolution = [loss for loss in loss_history]\n",
    "plt.plot(loss_evolution)\n",
    "plt.show()\n",
    "plt.plot(np.log(loss_evolution))\n",
    "plt.show()\n",
    "plt.plot(np.log(snr_history))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plu.plot_temporal_weights(inw)\n",
    "p = plu.plot_temporal_weights(outw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiw = inw * 10\n",
    "plu.plot_temporal_weights(tiw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tiw.flatten(),bins=500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(inw.flatten(),bins=500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(outw.flatten(),bins=500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_memory():\n",
    "    import collections, gc, torch\n",
    "    tensors = collections.Counter((str(o.device), o.dtype, tuple(o.shape))\n",
    "                                  for o in gc.get_objects()\n",
    "                                  if torch.is_tensor(o))\n",
    "    for line in sorted(tensors.items()):\n",
    "        print('{}\\t{}'.format(*line))\n",
    "debug_memory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name)\n",
    "    if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "        inw = np.array(parameter.squeeze().detach().cpu())\n",
    "    elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "        outw = np.array(parameter.squeeze().detach().cpu())\n",
    "    #elif(name=='tconv.weight_g'):\n",
    "    #    print(np.shape(np.array(parameter.squeeze().detach())))\n",
    "\n",
    "#print(inw.shape)\n",
    "#print(bias.shape)\n",
    "#print(wnorm.shape)\n",
    "#print(outw.shape)\n",
    "p = plu.plot_temporal_weights(inw)\n",
    "p = plu.plot_temporal_weights(outw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(inw.flatten())\n",
    "plt.hist(outw.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(plu)\n",
    "#movies = movie_batch[0]\n",
    "#recons = recon_batch[0]\n",
    "print('Movies:')\n",
    "for i in range(10):\n",
    "    plu.plot_movies_recons(np.squeeze(movie_batch), np.squeeze(recon_batch), i)\n",
    "    #plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inw.shape)\n",
    "print(np.max(inw))\n",
    "print(np.min(inw))\n",
    "for i in range(inw.shape[1]):\n",
    "    plt.imshow(inw[9,i,:,:],cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie.shape)\n",
    "m = movie[7,0,1,:,:]\n",
    "plt.imshow(m)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    moreepochs = 2000\n",
    "    print(f'Training for {moreepochs} more Epochs:')\n",
    "    for i in range(moreepochs):\n",
    "        start = time.time()\n",
    "        times = []\n",
    "        for movie in train_loader:\n",
    "            movie = torch.unsqueeze(movie,1)\n",
    "            #print(movie.size())\n",
    "            movie = movie.float().cuda()\n",
    "            optimizer.zero_grad()\n",
    "            acts = model.encode(movie)\n",
    "            recon = model.decode(acts)\n",
    "            loss = loss_func(movie, recon, acts)\n",
    "            loss_history.append(loss.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            end=time.time()\n",
    "            times.append(end-start)\n",
    "            \n",
    "        if((i+1)%printing_modulo==0):\n",
    "            print(f'{i+1}th Epoch (mean time per epoch: {round(np.mean(times))}s)')\n",
    "        else:\n",
    "            print('*',end='')\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aec():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(train_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.encode(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Recon Images')\n",
    "\n",
    "\n",
    "visualize_aec()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.make_grid(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "plt.ion()   # continuously plot\n",
    "\n",
    "# original data (first row) for viewing\n",
    "view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "    \n",
    "    \n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, b_label) in enumerate(train_loader):\n",
    "        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n",
    "        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.numpy())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            for i in range(N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "#\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEC()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
