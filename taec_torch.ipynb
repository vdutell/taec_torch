{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imp\n",
    "import time\n",
    "import os\n",
    "\n",
    "import utils.movie_readin as mru\n",
    "import utils.plotutils as plu\n",
    "import utils.model as mod\n",
    "#import utils.model_analysis as man\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:32^2  = 1024 pixels by 5 frames, to 100 hidden nodes for 10.24x compression\n"
     ]
    }
   ],
   "source": [
    "# movie parameters\n",
    "frame_rate = 120\n",
    "patch_size = 32\n",
    "patch_seconds = 5\n",
    "patch_frames = patch_seconds * frame_rate\n",
    "movies_folder = '/data/stationary_motion/pixel2xlmomentlens/pngs'\n",
    "patches_folder = f'/data/stationary_motion/pixel2xlmomentlens/patches/patches_{patch_size}px_{patch_seconds}s_{frame_rate}fps'\n",
    "\n",
    "# model hyperparameter\n",
    "lambda_activation = 0.1\n",
    "lambda_biophysical = 0\n",
    "conv_width = 8\n",
    "hidden_nodes = 100\n",
    "compression = patch_size**2 / hidden_nodes\n",
    "print(f'Model:{patch_size}^2  = {patch_size**2} pixels by {patch_seconds} frames, to {hidden_nodes} hidden nodes for {compression}x compression')\n",
    "\n",
    "# training parameters\n",
    "num_epochs = 100\n",
    "batch_sizes = [50]\n",
    "learning_rates = [1e-3]\n",
    "learning_momentum = 0.99\n",
    "savefolder = './output/actv_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Pre-computed natural movie patches. Loading them in...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "imp.reload(mru)\n",
    "# create movie patches if we haven't yet\n",
    "try:\n",
    "    os.stat(patches_folder)\n",
    "    print('Found Pre-computed natural movie patches. Loading them in...')\n",
    "except:\n",
    "    print('Couldn\\'t find natual movie patches. Making them...')\n",
    "    mru.createNatMoviePatches(framerate=frame_rate, patchsize=patch_size, seconds=patch_seconds,\n",
    "                          read_folder=movies_folder, write_folder=patches_folder, patches_per_file=100000)\n",
    "    print('Done Making Patches. Loading them in....')\n",
    "#movie_dataset = mru.NaturalMovieDataset(patches_folder)\n",
    "movie_dataset = mru.get_pkl_patch_movie(patches_folder)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:0.001; batch size:50\n",
      "Found GPU - Running Model on it.\n",
      "Training 100 Epochs. Estimated run time: 273.8mins.\n",
      "*"
     ]
    }
   ],
   "source": [
    "imp.reload(mod)\n",
    "imp.reload(mru)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    #train_loader = mru.DataLoader(movie_dataset, batch_size=batch_size,\n",
    "    #                    shuffle=True, num_workers=8)\n",
    "    # for now: read all movies in:\n",
    "    #movies_as_array = movie_dataset.getallitems()\n",
    "    \n",
    "    for learning_rate in learning_rates:\n",
    "        \n",
    "        print(f'Learning Rate:{learning_rate}; batch size:{batch_size}')\n",
    "        # our model\n",
    "        model = mod.AEC(hidden_nodes, conv_width, patch_size, lambda_activation).double()\n",
    "        #model = nn.DataParallel(model).cuda()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            print('Found GPU - Running Model on it.')\n",
    "            model.cuda()\n",
    "        else:\n",
    "            print('No GPUs found. Training on CPUs.')\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.5)#, momentum=learning_momentum)\n",
    "        #optimizer = optim.SGD(model.parameters(), lr=learning_rate)#, momentum=learning_momentum)\n",
    "\n",
    "        print_epocs = 20\n",
    "        printing_modulo = num_epochs/print_epocs\n",
    "        loss_history = []\n",
    "        snr_history = []\n",
    "        print(f'Training {num_epochs} Epochs. ',end=\"\")\n",
    "        # Because dataset is small and all in one .pkl file, it's faster to read all into memory \n",
    "        for i in range(num_epochs):\n",
    "            start = time.time()\n",
    "            times = []\n",
    "            batches_start = np.arange(0,np.shape(movie_dataset)[0], batch_size)\n",
    "            for bs in batches_start:\n",
    "                movie_batch = torch.unsqueeze(torch.tensor(movie_dataset[bs:bs+batch_size]),1).cuda()          \n",
    "                optimizer.zero_grad() #zero out our gradients\n",
    "                acts = model.encode(movie_batch)\n",
    "                recon_batch = model.decode(acts)\n",
    "                loss = model.loss_func(movie_batch, recon_batch, acts)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                end = time.time()\n",
    "                times.append(end-start)\n",
    "            # record loss and snr after each epoch\n",
    "            loss_history.append(loss.item())\n",
    "            snr_history.append(model.calc_snr(movie_batch, recon_batch).detach())\n",
    "            # if it's our first iteration, \n",
    "            if(True):\n",
    "                params = f'lr{learning_rate}_bs{batch_size}'\n",
    "                if(i==0):\n",
    "                    print(f'Estimated run time: {round(times[-1]*num_epochs/60,1)}mins.')\n",
    "                elif((i+1)%printing_modulo==0):\n",
    "                    print(f'Epoch {i+1}/{num_epochs} (mean time per epoch: {round(np.mean(times),1)}s)')\n",
    "                    for name, parameter in model.named_parameters():\n",
    "                        print(name)\n",
    "                        if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "                            inw = np.array(parameter.cpu().squeeze().detach())\n",
    "                            break\n",
    "                    p = plu.plot_temporal_weights(inw)\n",
    "                    plt.savefig(f'{savefolder}inw_{params}_{round(i/num_epochs,2)}.png')\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print('*',end='')\n",
    "\n",
    "        loss_evolution = [np.float(loss.detach()) for loss in loss_history]\n",
    "        snr_evolution =  [np.float(snr.detach()) for snr in snr_history]\n",
    "        # plot evolution of loss and snr\n",
    "        p = plt.plot(loss_evolution)\n",
    "        plt.title('Loss Evolution')\n",
    "        plt.savefig(f'{savefolder}loss_{params}.png')\n",
    "        plt.clf()\n",
    "        p = plt.plot(np.log(loss_evolution))\n",
    "        plt.title('LogLoss Evolution')\n",
    "        plt.savefig(f'{savefolder}logloss_{params}.png')\n",
    "        plt.clf()\n",
    "        p = plt.plot(snr_evolution)\n",
    "        plt.title('SNR Evolution')\n",
    "        plt.savefig(f'{savefolder}snr_{params}.png')\n",
    "        plt.clf()\n",
    "\n",
    "        for name, parameter in model.named_parameters():\n",
    "            if(name in ['tconv.module.weight_v', 'tconv.weight_v']):\n",
    "                inw = np.array(parameter.cpu().squeeze().detach())\n",
    "            elif(name in ['tdeconv.module.weight', 'tdeconv.weight']):\n",
    "                outw = np.array(parameter.cpu().squeeze().detach())\n",
    "        \n",
    "        #mp = model.named_parameters()\n",
    "        #bias = np.array(next(mp).detach())\n",
    "        #wnorm = next(mp)\n",
    "        #inw = np.array(next(mp).squeeze().detach())\n",
    "        #outw = np.array(next(mp).squeeze().detach())\n",
    "\n",
    "        p = plu.plot_temporal_weights(inw)\n",
    "        plt.savefig(f'{savefolder}inw_{params}.png')\n",
    "        plt.clf()\n",
    "        p = plu.plot_temporal_weights(outw)\n",
    "        plt.savefig(f'{savefolder}outw_{params}.png')\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "        print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_memory():\n",
    "    import collections, gc, torch\n",
    "    tensors = collections.Counter((str(o.device), o.dtype, tuple(o.shape))\n",
    "                                  for o in gc.get_objects()\n",
    "                                  if torch.is_tensor(o))\n",
    "    for line in sorted(tensors.items()):\n",
    "        print('{}\\t{}'.format(*line))\n",
    "debug_memory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_evolution = [np.float(loss.detach()) for loss in loss_history]\n",
    "plt.plot(loss_evolution)\n",
    "plt.show()\n",
    "plt.plot(np.log(loss_evolution))\n",
    "plt.show()\n",
    "plt.plot(np.log(snr_history))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name)\n",
    "    if(name=='tconv.module.weight_v'):\n",
    "        inw = np.array(parameter.squeeze().detach().cpu())\n",
    "    elif(name=='tdeconv.module.weight'):\n",
    "        outw = np.array(parameter.squeeze().detach().cpu())\n",
    "    #elif(name=='tconv.weight_g'):\n",
    "    #    print(np.shape(np.array(parameter.squeeze().detach())))\n",
    "\n",
    "#print(inw.shape)\n",
    "#print(bias.shape)\n",
    "#print(wnorm.shape)\n",
    "#print(outw.shape)\n",
    "p = plu.plot_temporal_weights(inw)\n",
    "p = plu.plot_temporal_weights(outw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(inw.flatten())\n",
    "plt.hist(outw.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(plu)\n",
    "#movies = movie_batch[0]\n",
    "#recons = recon_batch[0]\n",
    "print('Movies:')\n",
    "for i in range(10):\n",
    "    plu.plot_movies_recons(np.squeeze(movie_batch), np.squeeze(recon_batch), i)\n",
    "    #plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inw.shape)\n",
    "print(np.max(inw))\n",
    "print(np.min(inw))\n",
    "for i in range(inw.shape[1]):\n",
    "    plt.imshow(inw[9,i,:,:],cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie.shape)\n",
    "m = movie[7,0,1,:,:]\n",
    "plt.imshow(m)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    moreepochs = 2000\n",
    "    print(f'Training for {moreepochs} more Epochs:')\n",
    "    for i in range(moreepochs):\n",
    "        start = time.time()\n",
    "        times = []\n",
    "        for movie in train_loader:\n",
    "            movie = torch.unsqueeze(movie,1)\n",
    "            #print(movie.size())\n",
    "            movie = movie.float().cuda()\n",
    "            optimizer.zero_grad()\n",
    "            acts = model.encode(movie)\n",
    "            recon = model.decode(acts)\n",
    "            loss = loss_func(movie, recon, acts)\n",
    "            loss_history.append(loss.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            end=time.time()\n",
    "            times.append(end-start)\n",
    "            \n",
    "        if((i+1)%printing_modulo==0):\n",
    "            print(f'{i+1}th Epoch (mean time per epoch: {round(np.mean(times))}s)')\n",
    "        else:\n",
    "            print('*',end='')\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aec():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(train_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.encode(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Recon Images')\n",
    "\n",
    "\n",
    "visualize_aec()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.make_grid(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "plt.ion()   # continuously plot\n",
    "\n",
    "# original data (first row) for viewing\n",
    "view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "    \n",
    "    \n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, b_label) in enumerate(train_loader):\n",
    "        b_x = x.view(-1, 28*28)   # batch x, shape (batch, 28*28)\n",
    "        b_y = x.view(-1, 28*28)   # batch y, shape (batch, 28*28)\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.numpy())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            for i in range(N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "#\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEC()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
